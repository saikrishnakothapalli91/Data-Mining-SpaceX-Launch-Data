{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362a883e-08bc-4b71-b2d6-3f4c16dc6093",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e32ddb8-e23e-4552-a64e-b170b48aae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a0c85-081b-4938-bdaa-4d284d085b65",
   "metadata": {},
   "source": [
    "## Step 2: Load the data (replace the file path with your local file path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e435aa-bbba-4468-a89d-de4eb521b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SpaceX_Falcon9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858e714-d28e-44f9-aab1-e66fd5ba3d85",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767a6214-4474-4c86-aab1-b16195dc8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' to datetime (if required)\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Optionally, create a new column for the number of days since the first launch\n",
    "df['DaysSinceLaunch'] = (df['Date'] - df['Date'].min()).dt.days\n",
    "\n",
    "# Drop the 'Date' column after converting it to a numeric feature\n",
    "df_encoded = df.drop('Date', axis=1)\n",
    "\n",
    "# One-hot encode categorical columns (e.g., 'Orbit', 'LaunchSite', etc.)\n",
    "categorical_columns = ['Orbit', 'LaunchSite', 'BoosterVersion', 'LandingPad', 'Serial']\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f92dd9-05d4-4e54-87b6-cf4154610369",
   "metadata": {},
   "source": [
    "## Step 4: Check the target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a84c5b-2ce4-4c3a-87e0-7a64e88aa816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target distribution:\n",
      "Outcome\n",
      "True ASDS      41\n",
      "None None      19\n",
      "True RTLS      14\n",
      "False ASDS      6\n",
      "True Ocean      5\n",
      "False Ocean     2\n",
      "None ASDS       2\n",
      "False RTLS      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df_encoded['Outcome']  # Target\n",
    "print(\"Original target distribution:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa715b9-cf0e-4bee-8f4c-3813d6ca588d",
   "metadata": {},
   "source": [
    "## Step 5: Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6441aaf-6661-4a91-82f5-3b184a8c7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('Outcome', axis=1)  # Features\n",
    "y = df_encoded['Outcome']  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db74c34-6cac-4fbe-987f-dd07765bd40e",
   "metadata": {},
   "source": [
    "## Step 6: Check if there are both classes in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12753987-727e-46f9-8d5a-ee25763e980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains both classes. Proceeding without resampling.\n"
     ]
    }
   ],
   "source": [
    "if len(y.value_counts()) == 1:\n",
    "    print(\"The dataset contains only one class. Handling imbalance using SMOTE...\")\n",
    "    # If only one class, apply SMOTE to balance the dataset\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    print(\"Resampled target class distribution:\")\n",
    "    print(pd.Series(y_res).value_counts())\n",
    "else:\n",
    "    print(\"The dataset contains both classes. Proceeding without resampling.\")\n",
    "    # If both classes exist, continue without SMOTE\n",
    "    X_res, y_res = X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13eee7f-a292-4453-a68e-4d6d4f1479e2",
   "metadata": {},
   "source": [
    "## Step 7: Impute missing values for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2435ce96-f640-449c-9922-024db4f00efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')  # Impute missing values using the median (for numerical columns)\n",
    "X_imputed = imputer.fit_transform(X_res)\n",
    "\n",
    "# Impute missing values for target (if necessary)\n",
    "y_imputed = SimpleImputer(strategy='most_frequent').fit_transform(y_res.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9564adc-4fa4-4834-bc28-62aef2ddb8a7",
   "metadata": {},
   "source": [
    "## Step 8: Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86521d14-4487-4ce1-9cc4-760d3106c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6ad69-a866-482d-8b5b-307904de3550",
   "metadata": {},
   "source": [
    "## Step 9: Train models on resampled data (if SMOTE was applied)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325f7580-a343-4e10-ac30-6ba84692db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef810134-8f5f-4841-8ea3-805e85eba0bc",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd5064e-4b19-493f-97b8-bf85dc207097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  False ASDS       0.00      0.00      0.00         1\n",
      " False Ocean       0.00      0.00      0.00         1\n",
      "   None None       0.50      1.00      0.67         2\n",
      "   True ASDS       0.64      1.00      0.78         7\n",
      "  True Ocean       0.00      0.00      0.00         2\n",
      "   True RTLS       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.36      0.43      0.37        18\n",
      "weighted avg       0.58      0.67      0.58        18\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  False ASDS       0.00      0.00      0.00         1\n",
      " False Ocean       0.00      0.00      0.00         1\n",
      "   None None       0.67      1.00      0.80         2\n",
      "   True ASDS       0.55      0.86      0.67         7\n",
      "  True Ocean       0.00      0.00      0.00         2\n",
      "   True RTLS       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.37      0.38      0.34        18\n",
      "weighted avg       0.56      0.56      0.51        18\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  False ASDS       0.00      0.00      0.00         1\n",
      " False Ocean       0.00      0.00      0.00         1\n",
      "   None None       0.50      1.00      0.67         2\n",
      "   True ASDS       0.70      1.00      0.82         7\n",
      "  True Ocean       0.00      0.00      0.00         2\n",
      "   True RTLS       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.37      0.43      0.37        18\n",
      "weighted avg       0.61      0.67      0.60        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
